{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Train Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
    "\n",
    "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Apply regularization techniques to your model. \n",
    "\n",
    "*Don't forgot to switch to GPU on Colab!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptJ2b3wk62Ud"
   },
   "source": [
    "## Regularization\n",
    "\n",
    "Using your best performing model from the previous module, apply each of the following regularization strategies: \n",
    "* Early Stopping\n",
    "* Dropout\n",
    "* Weight Decay\n",
    "* Weight Constraint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USXjs7Hk71Hy"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_quickdraw(path):\n",
    "    \"\"\"\n",
    "    Loads the data, normalizes it, splits into target and feature\n",
    "    Preforms train test split\n",
    "    @param path: path to data\n",
    "    returns : train test split tuple\n",
    "    \"\"\"\n",
    "    data = np.load('../quickdraw10.npz')\n",
    "    X = data['arr_0']\n",
    "    y = data['arr_1']\n",
    "    X = X  / 255\n",
    "    X, y = shuffle(X, y)\n",
    "    return train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_quickdraw(\"../quickdraw10.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "   1/2094 [..............................] - ETA: 0s - loss: 2.4521 - accuracy: 0.1562WARNING:tensorflow:From /home/allan/.local/share/virtualenvs/u4-s2-giZ6Z0KA/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0168s). Check your callbacks.\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.8167 - accuracy: 0.7599 - val_loss: 0.6738 - val_accuracy: 0.8065\n",
      "Epoch 2/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.6312 - accuracy: 0.8152 - val_loss: 0.6270 - val_accuracy: 0.8161\n",
      "Epoch 3/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.5808 - accuracy: 0.8292 - val_loss: 0.6058 - val_accuracy: 0.8225\n",
      "Epoch 4/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.5515 - accuracy: 0.8373 - val_loss: 0.5987 - val_accuracy: 0.8247\n",
      "Epoch 5/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.5307 - accuracy: 0.8444 - val_loss: 0.5897 - val_accuracy: 0.8298\n",
      "Epoch 6/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.5155 - accuracy: 0.8472 - val_loss: 0.5842 - val_accuracy: 0.8301\n",
      "Epoch 7/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.5020 - accuracy: 0.8527 - val_loss: 0.5905 - val_accuracy: 0.8275\n",
      "Epoch 8/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.4915 - accuracy: 0.8551 - val_loss: 0.5871 - val_accuracy: 0.8318\n",
      "Epoch 9/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.4834 - accuracy: 0.8564 - val_loss: 0.5755 - val_accuracy: 0.8351\n",
      "Epoch 10/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.4754 - accuracy: 0.8595 - val_loss: 0.5810 - val_accuracy: 0.8343\n",
      "Epoch 11/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.4671 - accuracy: 0.8617 - val_loss: 0.5882 - val_accuracy: 0.8323\n",
      "Epoch 12/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.4615 - accuracy: 0.8645 - val_loss: 0.5786 - val_accuracy: 0.8358\n",
      "Epoch 13/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.4551 - accuracy: 0.8667 - val_loss: 0.5830 - val_accuracy: 0.8371\n",
      "Epoch 14/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.4506 - accuracy: 0.8669 - val_loss: 0.5920 - val_accuracy: 0.8323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7c9034dac8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#['0.8365757465362549', 'adam', '0.001', '3', '32', '10', 'relu', 'softmax']\n",
    "logdir = os.path.join(\"logs\", \"EarlyStopping-Loss\")\n",
    "\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5)\n",
    "\n",
    "model = Sequential([Dense(32, input_dim=784, activation='relu'), Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=99, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c4d0b5824fce8c49\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c4d0b5824fce8c49\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "   1/2094 [..............................] - ETA: 0s - loss: 2.4135 - accuracy: 0.1875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_train_batch_end` time: 0.0231s). Check your callbacks.\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.9392 - accuracy: 0.7138 - val_loss: 0.7032 - val_accuracy: 0.7915\n",
      "Epoch 2/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.7664 - accuracy: 0.7709 - val_loss: 0.6623 - val_accuracy: 0.8058\n",
      "Epoch 3/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.7279 - accuracy: 0.7802 - val_loss: 0.6406 - val_accuracy: 0.8134\n",
      "Epoch 4/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.7013 - accuracy: 0.7871 - val_loss: 0.6282 - val_accuracy: 0.8147\n",
      "Epoch 5/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.6856 - accuracy: 0.7916 - val_loss: 0.6213 - val_accuracy: 0.8192\n",
      "Epoch 6/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6732 - accuracy: 0.7949 - val_loss: 0.6058 - val_accuracy: 0.8213\n",
      "Epoch 7/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.6607 - accuracy: 0.7977 - val_loss: 0.6130 - val_accuracy: 0.8185\n",
      "Epoch 8/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6544 - accuracy: 0.7976 - val_loss: 0.6060 - val_accuracy: 0.8228\n",
      "Epoch 9/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6437 - accuracy: 0.8022 - val_loss: 0.6088 - val_accuracy: 0.8211\n",
      "Epoch 10/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6388 - accuracy: 0.8034 - val_loss: 0.6025 - val_accuracy: 0.8238\n",
      "Epoch 11/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6309 - accuracy: 0.8041 - val_loss: 0.6028 - val_accuracy: 0.8221\n",
      "Epoch 12/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6285 - accuracy: 0.8063 - val_loss: 0.5956 - val_accuracy: 0.8257\n",
      "Epoch 13/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6238 - accuracy: 0.8080 - val_loss: 0.5985 - val_accuracy: 0.8231\n",
      "Epoch 14/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6186 - accuracy: 0.8102 - val_loss: 0.5959 - val_accuracy: 0.8262\n",
      "Epoch 15/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6134 - accuracy: 0.8108 - val_loss: 0.5944 - val_accuracy: 0.8260\n",
      "Epoch 16/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6122 - accuracy: 0.8097 - val_loss: 0.5956 - val_accuracy: 0.8270\n",
      "Epoch 17/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6076 - accuracy: 0.8125 - val_loss: 0.6000 - val_accuracy: 0.8245\n",
      "Epoch 18/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6050 - accuracy: 0.8133 - val_loss: 0.5954 - val_accuracy: 0.8259\n",
      "Epoch 19/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6016 - accuracy: 0.8144 - val_loss: 0.5942 - val_accuracy: 0.8274\n",
      "Epoch 20/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.5998 - accuracy: 0.8160 - val_loss: 0.5957 - val_accuracy: 0.8284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7d34cd4630>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", \"drop\")\n",
    "\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5)\n",
    "\n",
    "model = Sequential([Dense(32, input_dim=784, activation='relu'), Dropout(.2), Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=99, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7afceb07fc3a4c11\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7afceb07fc3a4c11\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "   1/2094 [..............................] - ETA: 0s - loss: 3.1260 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0240s). Check your callbacks.\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 1.0784 - accuracy: 0.7381 - val_loss: 0.9138 - val_accuracy: 0.7700\n",
      "Epoch 2/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.8881 - accuracy: 0.7791 - val_loss: 0.8517 - val_accuracy: 0.7873\n",
      "Epoch 3/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.8402 - accuracy: 0.7901 - val_loss: 0.8257 - val_accuracy: 0.7931\n",
      "Epoch 4/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.8058 - accuracy: 0.7987 - val_loss: 0.7960 - val_accuracy: 0.8013\n",
      "Epoch 5/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.7817 - accuracy: 0.8042 - val_loss: 0.7679 - val_accuracy: 0.8066\n",
      "Epoch 6/99\n",
      "2094/2094 [==============================] - 3s 2ms/step - loss: 0.7629 - accuracy: 0.8073 - val_loss: 0.7525 - val_accuracy: 0.8166\n",
      "Epoch 7/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.7476 - accuracy: 0.8130 - val_loss: 0.7510 - val_accuracy: 0.8099\n",
      "Epoch 8/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.7394 - accuracy: 0.8139 - val_loss: 0.7501 - val_accuracy: 0.8082\n",
      "Epoch 9/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.7299 - accuracy: 0.8158 - val_loss: 0.7407 - val_accuracy: 0.8110\n",
      "Epoch 10/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.7234 - accuracy: 0.8178 - val_loss: 0.7249 - val_accuracy: 0.8161\n",
      "Epoch 11/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.7157 - accuracy: 0.8194 - val_loss: 0.7129 - val_accuracy: 0.8224\n",
      "Epoch 12/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.7097 - accuracy: 0.8234 - val_loss: 0.7061 - val_accuracy: 0.8232\n",
      "Epoch 13/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.7057 - accuracy: 0.8228 - val_loss: 0.7103 - val_accuracy: 0.8252\n",
      "Epoch 14/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.7038 - accuracy: 0.8232 - val_loss: 0.7052 - val_accuracy: 0.8242\n",
      "Epoch 15/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.7010 - accuracy: 0.8250 - val_loss: 0.6985 - val_accuracy: 0.8267\n",
      "Epoch 16/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6964 - accuracy: 0.8250 - val_loss: 0.7100 - val_accuracy: 0.8220\n",
      "Epoch 17/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6946 - accuracy: 0.8262 - val_loss: 0.7230 - val_accuracy: 0.8178\n",
      "Epoch 18/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6917 - accuracy: 0.8272 - val_loss: 0.6953 - val_accuracy: 0.8292\n",
      "Epoch 19/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6911 - accuracy: 0.8278 - val_loss: 0.6946 - val_accuracy: 0.8263\n",
      "Epoch 20/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6886 - accuracy: 0.8283 - val_loss: 0.7179 - val_accuracy: 0.8206\n",
      "Epoch 21/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6887 - accuracy: 0.8288 - val_loss: 0.7262 - val_accuracy: 0.8118\n",
      "Epoch 22/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6875 - accuracy: 0.8281 - val_loss: 0.7011 - val_accuracy: 0.8227\n",
      "Epoch 23/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6870 - accuracy: 0.8274 - val_loss: 0.7096 - val_accuracy: 0.8212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7c90523ba8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", \"weight\")\n",
    "\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5)\n",
    "\n",
    "model = Sequential([Dense(32, input_dim=784, activation='relu',kernel_regularizer=regularizers.l2(0.01)), Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=99, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 29835), started 0:27:24 ago. (Use '!kill 29835' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-40f04f69b5bead1e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-40f04f69b5bead1e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "   1/2094 [..............................] - ETA: 0s - loss: 2.4636 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0288s). Check your callbacks.\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.8253 - accuracy: 0.7585 - val_loss: 0.6816 - val_accuracy: 0.8036\n",
      "Epoch 2/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.6479 - accuracy: 0.8114 - val_loss: 0.6307 - val_accuracy: 0.8166\n",
      "Epoch 3/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.5986 - accuracy: 0.8248 - val_loss: 0.6120 - val_accuracy: 0.8210\n",
      "Epoch 4/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.5705 - accuracy: 0.8330 - val_loss: 0.5967 - val_accuracy: 0.8269\n",
      "Epoch 5/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.5529 - accuracy: 0.8374 - val_loss: 0.5943 - val_accuracy: 0.8253\n",
      "Epoch 6/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.5381 - accuracy: 0.8414 - val_loss: 0.5776 - val_accuracy: 0.8306\n",
      "Epoch 7/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.5274 - accuracy: 0.8451 - val_loss: 0.5680 - val_accuracy: 0.8332\n",
      "Epoch 8/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.5174 - accuracy: 0.8479 - val_loss: 0.5633 - val_accuracy: 0.8372\n",
      "Epoch 9/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.5108 - accuracy: 0.8504 - val_loss: 0.5761 - val_accuracy: 0.8318\n",
      "Epoch 10/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.5055 - accuracy: 0.8504 - val_loss: 0.5580 - val_accuracy: 0.8402\n",
      "Epoch 11/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.4982 - accuracy: 0.8544 - val_loss: 0.5613 - val_accuracy: 0.8367\n",
      "Epoch 12/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.4948 - accuracy: 0.8547 - val_loss: 0.5623 - val_accuracy: 0.8385\n",
      "Epoch 13/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.4907 - accuracy: 0.8532 - val_loss: 0.5624 - val_accuracy: 0.8370\n",
      "Epoch 14/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.4872 - accuracy: 0.8564 - val_loss: 0.5668 - val_accuracy: 0.8357\n",
      "Epoch 15/99\n",
      "2094/2094 [==============================] - 4s 2ms/step - loss: 0.4868 - accuracy: 0.8561 - val_loss: 0.5637 - val_accuracy: 0.8382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7d34a64710>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", \"constrain\")\n",
    "\n",
    "wc = MaxNorm(max_value=2)\n",
    "\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5)\n",
    "\n",
    "model = Sequential([Dense(32, input_dim=784, activation='relu',kernel_constraint=wc), Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=99, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 29835), started 0:56:25 ago. (Use '!kill 29835' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6d5b99da458fe7f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6d5b99da458fe7f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pScpa3nRRxCN"
   },
   "source": [
    "## Deploy\n",
    "\n",
    "Save your model's weights using the Checkpoint function. Try reloading the model and making inference on your validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cqpHQt_SIbW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "\n",
      "Epoch 00001: saving model to weights_best.h5\n",
      "2094/2094 - 4s - loss: 0.8341 - accuracy: 0.7526 - val_loss: 0.6942 - val_accuracy: 0.7978\n",
      "Epoch 2/99\n",
      "\n",
      "Epoch 00002: saving model to weights_best.h5\n",
      "2094/2094 - 3s - loss: 0.6527 - accuracy: 0.8111 - val_loss: 0.6425 - val_accuracy: 0.8126\n",
      "Epoch 3/99\n",
      "\n",
      "Epoch 00003: saving model to weights_best.h5\n",
      "2094/2094 - 4s - loss: 0.6037 - accuracy: 0.8248 - val_loss: 0.6071 - val_accuracy: 0.8242\n",
      "Epoch 4/99\n",
      "\n",
      "Epoch 00004: saving model to weights_best.h5\n",
      "2094/2094 - 4s - loss: 0.5731 - accuracy: 0.8322 - val_loss: 0.5935 - val_accuracy: 0.8268\n",
      "Epoch 5/99\n",
      "\n",
      "Epoch 00005: saving model to weights_best.h5\n",
      "2094/2094 - 4s - loss: 0.5522 - accuracy: 0.8376 - val_loss: 0.5883 - val_accuracy: 0.8286\n",
      "Epoch 6/99\n",
      "\n",
      "Epoch 00006: saving model to weights_best.h5\n",
      "2094/2094 - 3s - loss: 0.5361 - accuracy: 0.8432 - val_loss: 0.5843 - val_accuracy: 0.8255\n",
      "Epoch 7/99\n",
      "\n",
      "Epoch 00007: saving model to weights_best.h5\n",
      "2094/2094 - 4s - loss: 0.5253 - accuracy: 0.8453 - val_loss: 0.5707 - val_accuracy: 0.8336\n",
      "Epoch 8/99\n",
      "\n",
      "Epoch 00008: saving model to weights_best.h5\n",
      "2094/2094 - 3s - loss: 0.5158 - accuracy: 0.8473 - val_loss: 0.5672 - val_accuracy: 0.8357\n",
      "Epoch 9/99\n",
      "\n",
      "Epoch 00009: saving model to weights_best.h5\n",
      "2094/2094 - 3s - loss: 0.5069 - accuracy: 0.8490 - val_loss: 0.5543 - val_accuracy: 0.8382\n",
      "Epoch 10/99\n",
      "\n",
      "Epoch 00010: saving model to weights_best.h5\n",
      "2094/2094 - 4s - loss: 0.5010 - accuracy: 0.8522 - val_loss: 0.5465 - val_accuracy: 0.8406\n",
      "Epoch 11/99\n",
      "\n",
      "Epoch 00011: saving model to weights_best.h5\n",
      "2094/2094 - 3s - loss: 0.4958 - accuracy: 0.8541 - val_loss: 0.5488 - val_accuracy: 0.8397\n",
      "Epoch 12/99\n",
      "\n",
      "Epoch 00012: saving model to weights_best.h5\n",
      "2094/2094 - 4s - loss: 0.4899 - accuracy: 0.8541 - val_loss: 0.5496 - val_accuracy: 0.8426\n",
      "Epoch 13/99\n",
      "\n",
      "Epoch 00013: saving model to weights_best.h5\n",
      "2094/2094 - 4s - loss: 0.4860 - accuracy: 0.8572 - val_loss: 0.5508 - val_accuracy: 0.8408\n",
      "Epoch 14/99\n",
      "\n",
      "Epoch 00014: saving model to weights_best.h5\n",
      "2094/2094 - 3s - loss: 0.4836 - accuracy: 0.8569 - val_loss: 0.5452 - val_accuracy: 0.8428\n",
      "Epoch 15/99\n",
      "\n",
      "Epoch 00015: saving model to weights_best.h5\n",
      "2094/2094 - 3s - loss: 0.4806 - accuracy: 0.8565 - val_loss: 0.5564 - val_accuracy: 0.8383\n",
      "Epoch 16/99\n",
      "\n",
      "Epoch 00016: saving model to weights_best.h5\n",
      "2094/2094 - 3s - loss: 0.4756 - accuracy: 0.8590 - val_loss: 0.5448 - val_accuracy: 0.8448\n",
      "Epoch 17/99\n",
      "\n",
      "Epoch 00017: saving model to weights_best.h5\n",
      "2094/2094 - 4s - loss: 0.4741 - accuracy: 0.8588 - val_loss: 0.5344 - val_accuracy: 0.8443\n",
      "Epoch 18/99\n",
      "\n",
      "Epoch 00018: saving model to weights_best.h5\n",
      "2094/2094 - 4s - loss: 0.4722 - accuracy: 0.8582 - val_loss: 0.5695 - val_accuracy: 0.8362\n",
      "Epoch 19/99\n",
      "\n",
      "Epoch 00019: saving model to weights_best.h5\n",
      "2094/2094 - 4s - loss: 0.4696 - accuracy: 0.8603 - val_loss: 0.5537 - val_accuracy: 0.8401\n",
      "Epoch 20/99\n",
      "\n",
      "Epoch 00020: saving model to weights_best.h5\n",
      "2094/2094 - 4s - loss: 0.4685 - accuracy: 0.8606 - val_loss: 0.5486 - val_accuracy: 0.8432\n",
      "Epoch 21/99\n",
      "\n",
      "Epoch 00021: saving model to weights_best.h5\n",
      "2094/2094 - 4s - loss: 0.4654 - accuracy: 0.8626 - val_loss: 0.5453 - val_accuracy: 0.8411\n",
      "Epoch 22/99\n",
      "\n",
      "Epoch 00022: saving model to weights_best.h5\n",
      "2094/2094 - 3s - loss: 0.4653 - accuracy: 0.8624 - val_loss: 0.5400 - val_accuracy: 0.8452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7d34943cf8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpoint = tf.keras.callbacks.ModelCheckpoint(\"weights_best.h5\",\n",
    "                                            verbose=1, \n",
    "                                            save_weights_only=True)\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential([Dense(32, input_dim=784, activation='relu',kernel_constraint=wc), Dense(10, activation='softmax')])\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=99, \n",
    "          validation_data=(X_test,y_test),\n",
    "          verbose=2,\n",
    "          callbacks=[cpoint, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032/1032 [==============================] - 1s 1ms/step - loss: 0.5400 - accuracy: 0.8452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5400391221046448, 0.8452121019363403]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = create_model()  # Start with same architecture\n",
    "m.load_weights('./weights_best.h5')  # Load instead of train\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032/1032 [==============================] - 1s 1ms/step - loss: 0.5400 - accuracy: 0.8452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5400391221046448, 0.8452121019363403]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKbr1gRg9BXs"
   },
   "source": [
    "### Stretch Goals\n",
    "- Mount your Google Drive to Colab to persist your model checkpoint files. \n",
    "- Research L2 normalization (weight decay)\n",
    "- Write a custom callback function to stop training after you reach .88 validation accuracy. \n",
    "- Select a new dataset and apply a neural network to it.\n",
    "- Research TensorFlow Serving\n",
    "- Play [QuickDraw](https://quickdraw.withgoogle.com/data)\n",
    "- Create a static webpage using TensorFlow.js to serve a model. Check out [Teachable Machine Learning](https://teachablemachine.withgoogle.com/) for ideas. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_434_Deploy_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
