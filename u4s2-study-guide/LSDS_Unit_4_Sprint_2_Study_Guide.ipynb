{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2mLZuEFWgrY6"
   },
   "source": [
    "<!-- \n",
    "Author: Brian Thomas Ross <ml@brianthomasross.com>\n",
    "License: BSD-3-Clause\n",
    "-->\n",
    "\n",
    "# Neural Network Foundations\n",
    "\n",
    "----\n",
    "\n",
    "This study guide should reinforce and provide practice for all the concepts you have seen in the past week. There are a mix of written question and coding exercises, both are equally important to prepare you for the sprint challenge, as well as being able to comfortably speak on these topics in interviews and on the job.\n",
    "\n",
    "If you get stuck or unsure of something remember the 20 minute rule. If that doesn't help then research a solution with [Google](https://www.google.com/) or [StackOverflow](https://wwww.stackoverflow.com/). Only once you have truly exhausted these methods should you turn to your Team Lead. They wont be there during the sprint challenge or during an interview. That being said, don't hesitate to ask for help if you truly are stuck.\n",
    "\n",
    "Have fun!\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cXdNncKph7PS"
   },
   "source": [
    "## Definitions\n",
    "\n",
    "Use your own words to define the following terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gYfMsaXMiMfm"
   },
   "source": [
    "### Input Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "45ZGRAiwiMdO"
   },
   "source": [
    "The 1st layer of the nueral net which has n nodes where n is equal to the number of inputs being recieved. This is implicitly defind when creating the 1st hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xnkeavm3iMY5"
   },
   "source": [
    "### Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3XI9_Z4liMWu"
   },
   "source": [
    "All layers that are not the input or output layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eaQz5joTiMUb"
   },
   "source": [
    "### Output Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "831G2buuiMSA"
   },
   "source": [
    "The final layer in the nueral net. This layer usually has a different activation function than the rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O4C2zwuxiMD_"
   },
   "source": [
    "### Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_2rY9EE9iMBo"
   },
   "source": [
    "An artificial neuron is a mathematical function. It takes one or more inputs that are multiplied by values called “weights” and added together. This value is then passed to a non-linear function, known as an activation function, to become the neuron's output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1BpTrJWiL_N"
   },
   "source": [
    "### Weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fRuN64XDiL87"
   },
   "source": [
    "How much importance a node has, this i learned and adjusted after each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KIzxvqcliaBa"
   },
   "source": [
    "### Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k71r029FiZ_N"
   },
   "source": [
    "A scalar  for the aactivation function allowing it to fit all the data better through overfitting or underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FpW0FPFkiZ-D"
   },
   "source": [
    "### Acitivation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BlpU1Qa8iZ7r"
   },
   "source": [
    "Normalizes the data in classification problems. Controls how active a nueron is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YQ4H7hu7iZ5N"
   },
   "source": [
    "### Node Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E1UXX7q0iZ26"
   },
   "source": [
    "The image that shows how each layer is connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_oK9gvviZ1C"
   },
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XrpGD0GOiZyx"
   },
   "source": [
    "Classification net?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OWyEK7PziZv5"
   },
   "source": [
    "### Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sGelGaRLiZs8"
   },
   "source": [
    "One pass through the network when training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZcPz7fliZp0"
   },
   "source": [
    "### Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFmCxRVvglrP"
   },
   "source": [
    "A net that only goes forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8tuJhVJ7ityO"
   },
   "source": [
    "### Back Propogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "78pvOoJPiuLp"
   },
   "source": [
    "The process of adjusting weights at the end of each epoch, you multiply some mean by the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KLErlhhoi3kl"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XwiPqcW_itvZ"
   },
   "source": [
    "## Concepts\n",
    "\n",
    "Answer the following questions using your own words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhtieWU0i6yQ"
   },
   "source": [
    "### Casually explain the steps involved to go from input to output in a simple neural network. How are predictions generated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbIyfH1Hj-aG"
   },
   "source": [
    "1st the weights are randomly assigned and the data is ingested. Next the hidden layers try to learn the importance of the nodes preceeding them such that we can adjust their weights and biases later. When you get to the output layer we use backpropogation to adjust the weights and biases. Rinse and repeat. Predictions are made by passing the previous nodes weights and biases through an activation function then passing that through the output layer's activation function.... dunno past this whats happening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hh17Eck3j-cV"
   },
   "source": [
    "### What kind of use cases exist for Neural Networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ml3oHS9okKQz"
   },
   "source": [
    "Anything with lots and lots of data but generallt images, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Fe_q81EkK49"
   },
   "source": [
    "### How does a neural network address the curse of dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qK6k8RHokLUD"
   },
   "source": [
    "Weights and biases are learned to reduce the importance of irrelevant deatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BbSi489UkLj9"
   },
   "source": [
    "### What are some potential pro / cons of using neural netowrks versus more traditional statistical models such as logistic regression or a decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKi9p-AQkLha"
   },
   "source": [
    "Long to train, maybe better maybe worse. Cool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BJRR0afFkLRF"
   },
   "source": [
    "### How would you determine the size of the input layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gErA43eekK2j"
   },
   "source": [
    "Number of inputs you have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ryPkPZFhpIWL"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rCqU2sEqpKwl"
   },
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WProsWxgrOgp"
   },
   "source": [
    "This is an open ended challenge using the titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hCS6M0syrPPC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "import time\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MYdRpDA-XvO3"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "train_csv = 'train.csv'\n",
    "test_csv = 'test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_csv, index_col='PassengerId')\n",
    "test_df = pd.read_csv(test_csv, index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OMYbm2LXYqYk"
   },
   "outputs": [],
   "source": [
    "# You'll probably need to do some wrangling\n",
    "\n",
    "def wrangle(df):\n",
    "    df.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "    df['Sex'] = df['Sex'].replace({'male': 1, 'female': 0})\n",
    "    transformer = make_column_transformer(\n",
    "        [('ohe', OneHotEncoder(use_cat_names=True), ['Embarked']),\n",
    "         ('impute', SimpleImputer(), ['Age'])],\n",
    "         remainder='passthrough', n_jobs=-1)\n",
    "    transformer.fit_transform(df)\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All estimators should implement fit and transform, or can be 'drop' or 'passthrough' specifiers. '('ohe', OneHotEncoder(cols=None, drop_invariant=False, handle_missing='value',\n              handle_unknown='value', return_df=True, use_cat_names=True,\n              verbose=0), ['Embarked'])' (type <class 'tuple'>) doesn't.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-68b261c4d897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-712a22a958e2>\u001b[0m in \u001b[0;36mwrangle\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      8\u001b[0m          ('impute', SimpleImputer(), ['Age'])],\n\u001b[1;32m      9\u001b[0m          remainder='passthrough', n_jobs=-1)\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/u4-s2-giZ6Z0KA/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[1;32m    463\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/u4-s2-giZ6Z0KA/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_validate_transformers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m                                 \u001b[0;34m\"transform, or can be 'drop' or 'passthrough' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                                 \u001b[0;34m\"specifiers. '%s' (type %s) doesn't.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                                 (t, type(t)))\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_column_callables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: All estimators should implement fit and transform, or can be 'drop' or 'passthrough' specifiers. '('ohe', OneHotEncoder(cols=None, drop_invariant=False, handle_missing='value',\n              handle_unknown='value', return_df=True, use_cat_names=True,\n              verbose=0), ['Embarked'])' (type <class 'tuple'>) doesn't."
     ]
    }
   ],
   "source": [
    "x = wrangle(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZ-rthmsY_lh"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-6c1d6d707672>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-6c1d6d707672>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    X =  # hint fit_transform\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Split and scale the data\n",
    "\n",
    "X = train_df.drop(['Survived'], axis=1).values.astype(float)\n",
    "\n",
    "\n",
    "ss = StandardScaler()\n",
    "X =  # hint fit_transform\n",
    "Y =  # hint just the Y 'values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rcRvHW3ZZdl"
   },
   "outputs": [],
   "source": [
    "# define a create_model function\n",
    "\n",
    "def create_model(#  hint: think about hyperparameter tuning \n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h_GHCzYkaHpr"
   },
   "outputs": [],
   "source": [
    "#  Tune at least 2 hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tx-NNh9SaP-K"
   },
   "outputs": [],
   "source": [
    "# Show your results - you probably didn't do well and that's okay."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LSDS-Unit-4-Sprint-2-Study-Guide.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
